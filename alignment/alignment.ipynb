{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import shlex\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import textgrid\n",
    "import sox\n",
    "import time\n",
    "import datetime\n",
    "import pydub\n",
    "from pydub.playback import play\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_set = set([\"up\", \"down\", \"three\", \"yes\", \"no\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112008\n"
     ]
    }
   ],
   "source": [
    "keywords = pd.read_csv(\"../keywords_listen.tsv\", sep=\"\\t\")\n",
    "print(keywords.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:for keyword yes, there are not enough examples to sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword right : 2000\n",
      "Keyword on : 2000\n",
      "Keyword stop : 2000\n",
      "Keyword go : 2000\n",
      "Keyword up : 2000\n",
      "Keyword left : 2000\n",
      "Keyword three : 2000\n",
      "Keyword no : 2000\n",
      "Keyword off : 2000\n",
      "Keyword yes : 1243\n",
      "Keyword down : 2000\n"
     ]
    }
   ],
   "source": [
    "# select examples each from keywords where the column [\"keywords\"] == True\n",
    "NUM_SAMPLES = 2000\n",
    "samples = {}\n",
    "for k in keywords_set:\n",
    "    if keywords[k].value_counts().loc[True] > NUM_SAMPLES:\n",
    "        #are there more than NUM_SAMPLES examples?\n",
    "        samples[k] = keywords[keywords[k]].sample(n=NUM_SAMPLES)\n",
    "    else:\n",
    "        # use them all\n",
    "        samples[k] = keywords[keywords[k]].copy()\n",
    "        logging.warning(f\"for keyword {k}, there are not enough examples to sample\")\n",
    "    print(\"Keyword\", k, \":\", samples[k].shape[0])    \n",
    "    \n",
    "# clean up each df by removing the keyword columns\n",
    "for k in samples.keys():\n",
    "    samples[k].drop(columns=keywords_set, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>6055e19ee9a2bccd2070499b4511a2c219b44e31fe4871...</td>\n",
       "      <td>common_voice_en_17393438.mp3</td>\n",
       "      <td>Yes, it would be difficult.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>a43bcfd1d7ad35f4ae5774295f97d0026b8a507cd8caf5...</td>\n",
       "      <td>common_voice_en_15733861.mp3</td>\n",
       "      <td>Yes, this is the right place.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             client_id  \\\n",
       "154  6055e19ee9a2bccd2070499b4511a2c219b44e31fe4871...   \n",
       "260  a43bcfd1d7ad35f4ae5774295f97d0026b8a507cd8caf5...   \n",
       "\n",
       "                             path                       sentence  up_votes  \\\n",
       "154  common_voice_en_17393438.mp3    Yes, it would be difficult.         2   \n",
       "260  common_voice_en_15733861.mp3  Yes, this is the right place.         2   \n",
       "\n",
       "     down_votes       age gender accent  \n",
       "154           0       NaN    NaN    NaN  \n",
       "260           1  fourties   male     us  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[\"yes\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mark/tinyspeech_harvard/tinyspeech/alignment\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "aligner.exceptions.CorpusError: Files with the same file name are not permitted. Files with the same name are: /work/input/clips/drei/common_voice_de_17324140.wav, /work/input/clips/links/common_voice_de_17324140.wav.\n",
    "```\n",
    "\n",
    "`Geh hinunter und hilf deinem Vater!` contains both `geh` and `hinunter`\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "set()\n",
      "on\n",
      "{'common_voice_en_589566.mp3', 'common_voice_en_17785868.mp3', 'common_voice_en_18314533.mp3', 'common_voice_en_19453947.mp3', 'common_voice_en_101144.mp3', 'common_voice_en_567048.mp3', 'common_voice_en_620842.mp3', 'common_voice_en_60790.mp3', 'common_voice_en_49347.mp3', 'common_voice_en_668361.mp3'}\n",
      "stop\n",
      "{'common_voice_en_17268545.mp3', 'common_voice_en_18153977.mp3', 'common_voice_en_19137764.mp3', 'common_voice_en_18166159.mp3', 'common_voice_en_177128.mp3', 'common_voice_en_17693248.mp3', 'common_voice_en_697828.mp3', 'common_voice_en_550291.mp3', 'common_voice_en_17296130.mp3', 'common_voice_en_19187812.mp3', 'common_voice_en_17249223.mp3', 'common_voice_en_94242.mp3', 'common_voice_en_612695.mp3', 'common_voice_en_17959405.mp3', 'common_voice_en_17258356.mp3'}\n",
      "go\n",
      "{'common_voice_en_51486.mp3', 'common_voice_en_528690.mp3', 'common_voice_en_18656241.mp3', 'common_voice_en_17369478.mp3', 'common_voice_en_585081.mp3', 'common_voice_en_174153.mp3', 'common_voice_en_504790.mp3', 'common_voice_en_18454441.mp3', 'common_voice_en_205156.mp3', 'common_voice_en_130303.mp3', 'common_voice_en_17884833.mp3', 'common_voice_en_17264714.mp3', 'common_voice_en_219217.mp3', 'common_voice_en_598798.mp3', 'common_voice_en_481072.mp3', 'common_voice_en_667432.mp3', 'common_voice_en_72293.mp3', 'common_voice_en_18144886.mp3'}\n",
      "up\n",
      "{'common_voice_en_693001.mp3', 'common_voice_en_13166.mp3', 'common_voice_en_523128.mp3', 'common_voice_en_18861297.mp3', 'common_voice_en_519644.mp3', 'common_voice_en_19677503.mp3', 'common_voice_en_528118.mp3', 'common_voice_en_66525.mp3', 'common_voice_en_18124855.mp3', 'common_voice_en_18509000.mp3', 'common_voice_en_158409.mp3', 'common_voice_en_220284.mp3', 'common_voice_en_19374151.mp3', 'common_voice_en_180994.mp3', 'common_voice_en_115059.mp3', 'common_voice_en_18648591.mp3', 'common_voice_en_18493270.mp3', 'common_voice_en_545238.mp3', 'common_voice_en_522491.mp3', 'common_voice_en_57516.mp3', 'common_voice_en_130373.mp3'}\n",
      "left\n",
      "{'common_voice_en_562520.mp3', 'common_voice_en_19728479.mp3', 'common_voice_en_625700.mp3', 'common_voice_en_18986143.mp3', 'common_voice_en_20130809.mp3', 'common_voice_en_19055630.mp3', 'common_voice_en_17309460.mp3', 'common_voice_en_19314596.mp3', 'common_voice_en_17298092.mp3', 'common_voice_en_17283568.mp3', 'common_voice_en_19028352.mp3', 'common_voice_en_14640.mp3', 'common_voice_en_17456676.mp3', 'common_voice_en_18066560.mp3', 'common_voice_en_549519.mp3', 'common_voice_en_598284.mp3', 'common_voice_en_605671.mp3', 'common_voice_en_2300.mp3', 'common_voice_en_46339.mp3', 'common_voice_en_17562459.mp3', 'common_voice_en_17288454.mp3', 'common_voice_en_19165918.mp3', 'common_voice_en_513543.mp3', 'common_voice_en_195889.mp3', 'common_voice_en_577309.mp3', 'common_voice_en_19795809.mp3', 'common_voice_en_18870349.mp3', 'common_voice_en_19995758.mp3'}\n",
      "three\n",
      "{'common_voice_en_661156.mp3', 'common_voice_en_19647184.mp3', 'common_voice_en_598138.mp3', 'common_voice_en_17265371.mp3', 'common_voice_en_18780212.mp3', 'common_voice_en_17284303.mp3', 'common_voice_en_18874118.mp3', 'common_voice_en_18471373.mp3', 'common_voice_en_17286673.mp3', 'common_voice_en_17288345.mp3', 'common_voice_en_17291953.mp3', 'common_voice_en_18887006.mp3'}\n",
      "no\n",
      "{'common_voice_en_15734023.mp3', 'common_voice_en_110571.mp3', 'common_voice_en_31339.mp3', 'common_voice_en_633421.mp3', 'common_voice_en_136032.mp3', 'common_voice_en_18861118.mp3', 'common_voice_en_490916.mp3', 'common_voice_en_20120559.mp3', 'common_voice_en_682981.mp3', 'common_voice_en_158699.mp3', 'common_voice_en_508944.mp3', 'common_voice_en_19966668.mp3', 'common_voice_en_247368.mp3', 'common_voice_en_18862195.mp3', 'common_voice_en_19609665.mp3', 'common_voice_en_184492.mp3', 'common_voice_en_603819.mp3', 'common_voice_en_517096.mp3', 'common_voice_en_17632239.mp3', 'common_voice_en_499915.mp3', 'common_voice_en_18596146.mp3', 'common_voice_en_675278.mp3', 'common_voice_en_185549.mp3', 'common_voice_en_602970.mp3', 'common_voice_en_1344704.mp3'}\n",
      "off\n",
      "{'common_voice_en_18509009.mp3', 'common_voice_en_780.mp3', 'common_voice_en_625700.mp3', 'common_voice_en_19841046.mp3', 'common_voice_en_20130809.mp3', 'common_voice_en_17334598.mp3', 'common_voice_en_608395.mp3', 'common_voice_en_19055630.mp3', 'common_voice_en_679466.mp3', 'common_voice_en_205719.mp3', 'common_voice_en_206591.mp3', 'common_voice_en_167402.mp3', 'common_voice_en_640432.mp3', 'common_voice_en_626956.mp3', 'common_voice_en_513050.mp3', 'common_voice_en_547987.mp3', 'common_voice_en_19703025.mp3', 'common_voice_en_588065.mp3', 'common_voice_en_206219.mp3', 'common_voice_en_145556.mp3', 'common_voice_en_19286022.mp3', 'common_voice_en_143910.mp3', 'common_voice_en_299590.mp3', 'common_voice_en_444295.mp3', 'common_voice_en_17280261.mp3', 'common_voice_en_17389565.mp3', 'common_voice_en_650299.mp3', 'common_voice_en_17899358.mp3', 'common_voice_en_31376.mp3', 'common_voice_en_101794.mp3', 'common_voice_en_100641.mp3', 'common_voice_en_152171.mp3', 'common_voice_en_18144220.mp3', 'common_voice_en_125.mp3', 'common_voice_en_672861.mp3', 'common_voice_en_18884759.mp3', 'common_voice_en_92966.mp3', 'common_voice_en_18994871.mp3', 'common_voice_en_18658573.mp3', 'common_voice_en_27895.mp3', 'common_voice_en_243894.mp3', 'common_voice_en_207424.mp3', 'common_voice_en_19411369.mp3', 'common_voice_en_678093.mp3', 'common_voice_en_18814900.mp3', 'common_voice_en_24806.mp3', 'common_voice_en_78188.mp3', 'common_voice_en_14356541.mp3', 'common_voice_en_17849226.mp3', 'common_voice_en_115784.mp3'}\n",
      "yes\n",
      "{'common_voice_en_16048263.mp3', 'common_voice_en_18269869.mp3', 'common_voice_en_17301556.mp3', 'common_voice_en_17291548.mp3', 'common_voice_en_18278302.mp3', 'common_voice_en_18530337.mp3', 'common_voice_en_18093118.mp3', 'common_voice_en_17283356.mp3', 'common_voice_en_18519676.mp3', 'common_voice_en_18505820.mp3', 'common_voice_en_3385728.mp3', 'common_voice_en_17256901.mp3', 'common_voice_en_17252554.mp3', 'common_voice_en_18341284.mp3', 'common_voice_en_18443961.mp3', 'common_voice_en_18493016.mp3', 'common_voice_en_17270561.mp3', 'common_voice_en_17264518.mp3', 'common_voice_en_19698102.mp3', 'common_voice_en_17436006.mp3', 'common_voice_en_17246981.mp3', 'common_voice_en_17261511.mp3', 'common_voice_en_17959389.mp3', 'common_voice_en_17825999.mp3', 'common_voice_en_18433605.mp3', 'common_voice_en_17861308.mp3', 'common_voice_en_18409678.mp3', 'common_voice_en_18355824.mp3', 'common_voice_en_11659332.mp3', 'common_voice_en_17897039.mp3', 'common_voice_en_18429178.mp3', 'common_voice_en_18480049.mp3', 'common_voice_en_18488121.mp3', 'common_voice_en_19156939.mp3', 'common_voice_en_17429863.mp3', 'common_voice_en_18454256.mp3', 'common_voice_en_17272845.mp3', 'common_voice_en_18066538.mp3', 'common_voice_en_17259270.mp3', 'common_voice_en_17488646.mp3'}\n",
      "down\n",
      "{'common_voice_en_83626.mp3', 'common_voice_en_173435.mp3', 'common_voice_en_562770.mp3', 'common_voice_en_88771.mp3', 'common_voice_en_129963.mp3', 'common_voice_en_218659.mp3', 'common_voice_en_514186.mp3', 'common_voice_en_17849282.mp3', 'common_voice_en_18163977.mp3', 'common_voice_en_628146.mp3', 'common_voice_en_18483693.mp3', 'common_voice_en_647481.mp3', 'common_voice_en_210493.mp3', 'common_voice_en_620047.mp3', 'common_voice_en_42179.mp3', 'common_voice_en_65125.mp3', 'common_voice_en_533536.mp3', 'common_voice_en_95452.mp3', 'common_voice_en_42831.mp3', 'common_voice_en_215538.mp3', 'common_voice_en_620689.mp3', 'common_voice_en_52290.mp3', 'common_voice_en_17505586.mp3', 'common_voice_en_130303.mp3', 'common_voice_en_194362.mp3', 'common_voice_en_211391.mp3', 'common_voice_en_15904130.mp3', 'common_voice_en_17877056.mp3', 'common_voice_en_623733.mp3', 'common_voice_en_483895.mp3', 'common_voice_en_18400941.mp3', 'common_voice_en_641388.mp3', 'common_voice_en_17999934.mp3', 'common_voice_en_155833.mp3', 'common_voice_en_484195.mp3', 'common_voice_en_3217.mp3', 'common_voice_en_18762133.mp3', 'common_voice_en_655473.mp3', 'common_voice_en_132785.mp3', 'common_voice_en_28995.mp3', 'common_voice_en_10404.mp3', 'common_voice_en_219217.mp3', 'common_voice_en_647756.mp3', 'common_voice_en_18442179.mp3', 'common_voice_en_18105059.mp3', 'common_voice_en_699959.mp3', 'common_voice_en_503110.mp3', 'common_voice_en_144327.mp3', 'common_voice_en_593535.mp3', 'common_voice_en_155980.mp3', 'common_voice_en_478849.mp3', 'common_voice_en_10208974.mp3', 'common_voice_en_544516.mp3', 'common_voice_en_596848.mp3', 'common_voice_en_655874.mp3', 'common_voice_en_628299.mp3', 'common_voice_en_18003828.mp3', 'common_voice_en_547413.mp3', 'common_voice_en_17245711.mp3', 'common_voice_en_89692.mp3', 'common_voice_en_634021.mp3', 'common_voice_en_648588.mp3', 'common_voice_en_247380.mp3', 'common_voice_en_663918.mp3', 'common_voice_en_18561775.mp3', 'common_voice_en_495701.mp3', 'common_voice_en_544598.mp3', 'common_voice_en_508699.mp3', 'common_voice_en_669773.mp3', 'common_voice_en_610985.mp3', 'common_voice_en_9788.mp3', 'common_voice_en_19723687.mp3', 'common_voice_en_16057.mp3', 'common_voice_en_43952.mp3', 'common_voice_en_97878.mp3', 'common_voice_en_19590494.mp3', 'common_voice_en_565204.mp3', 'common_voice_en_565632.mp3', 'common_voice_en_666316.mp3', 'common_voice_en_18125786.mp3'}\n"
     ]
    }
   ],
   "source": [
    "# find files which contain more than one keyword\n",
    "#keywords_set = set([\"öffne\", \"hinunter\", \"drei\", \"ja\", \"nein\", \"links\", \"richtig\", \"auf\", \"aus\", \"halt\", \"geh\"])\n",
    "wavs = set()\n",
    "for kw in keywords_set:\n",
    "    # german\n",
    "    # wavlist = f\"../../alignment_processing/input/clips/{kw}/*.wav\"\n",
    "    # english\n",
    "    mp3list = f\"../../eleven_word_dataset/clips/{kw}/*.mp3\"\n",
    "    kw_clips = glob.glob(mp3list)\n",
    "    kw_clips = list(map(os.path.basename, kw_clips))\n",
    "    kw_clips = set(kw_clips)\n",
    "    print(kw)\n",
    "    print(kw_clips.intersection(wavs))\n",
    "    wavs.update(kw_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../eleven_word_dataset/clips/yes/common_voice_en_615206.mp3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw = \"yes\"\n",
    "wavlist = f\"../../eleven_word_dataset/clips/{kw}/*.mp3\"\n",
    "kw_wavs = glob.glob(wavlist)\n",
    "kw_wavs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for kw in keywords_set:\n",
    "#     dest = \"../../alignment_processing_en/extractions_silencepad/\"\n",
    "#     os.mkdir(dest + kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right 2000\n",
      "on 2000\n",
      "stop 2000\n",
      "go 2000\n",
      "up 2000\n",
      "left 2000\n",
      "three 2000\n",
      "no 2000\n",
      "off 2000\n",
      "yes 1243\n",
      "down 2000\n"
     ]
    }
   ],
   "source": [
    "for kw in keywords_set:\n",
    "    clips = f\"../../eleven_word_dataset/clips/{kw}/*.mp3\"\n",
    "    clips = glob.glob(clips)\n",
    "    print(kw, len(clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output_file: ../../alignment_processing_en/right/common_voice_en_53984.wav already exists and will be overwritten on build\n",
      "WARNING:sox:output_file: ../../alignment_processing_en/right/common_voice_en_53984.wav already exists and will be overwritten on build\n"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"caution: large fs operation\")\n",
    "ALIGNMENT_WORKDIR = \"../../alignment_processing_en/\"\n",
    "for kw in keywords_set:\n",
    "    clips = f\"../../eleven_word_dataset/clips/{kw}/*.mp3\"\n",
    "    clips = glob.glob(clips)\n",
    "    clips = list(map(os.path.basename, clips))\n",
    "    for clip in clips:\n",
    "        mp3_path = f\"../../eleven_word_dataset/clips/{kw}/{clip}\"\n",
    "        # row in df\n",
    "        row = keywords[keywords.path.str.match(clip)]\n",
    "        # directory to copy wav to\n",
    "        destdir = ALIGNMENT_WORKDIR + kw + os.path.sep\n",
    "        \n",
    "        filename_noext = os.path.splitext(clip)[0]\n",
    "        \n",
    "        dest = destdir + filename_noext + \".wav\"\n",
    "        \n",
    "        utterance = row.sentence.iloc[0]\n",
    "        transcription = f\"{ALIGNMENT_WORKDIR}{kw}/{filename_noext}.txt\"\n",
    "        \n",
    "        with open(transcription, 'w') as fh:\n",
    "            fh.write(utterance)\n",
    "        transformer = sox.Transformer()\n",
    "        transformer.convert(samplerate=16000)  # from 48K mp3s\n",
    "        transformer.build(mp3_path, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"caution: renames a lot of files\")\n",
    "# rename files to include the keyword (temporarily)\n",
    "keywords_set = set([\"öffne\", \"hinunter\", \"drei\", \"ja\", \"nein\", \"links\", \"richtig\", \"auf\", \"aus\", \"halt\", \"geh\"])\n",
    "for kw in keywords_set:\n",
    "    kw_wavs = glob.glob(f\"../../alignment_processing/input/clips/{kw}/*.wav\")\n",
    "    kw_txts = glob.glob(f\"../../alignment_processing/input/clips/{kw}/*.txt\")\n",
    "    for f in kw_wavs:\n",
    "        dirname, filename = os.path.split(f)\n",
    "        newdest = dirname + os.path.sep + f\"{kw}_\" + filename\n",
    "        os.rename(f, newdest)\n",
    "    for f in kw_txts:\n",
    "        dirname, filename = os.path.split(f)\n",
    "        newdest = dirname + os.path.sep + f\"{kw}_\" + filename\n",
    "        os.rename(f, newdest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../alignment_processing/input/clips/offne/offne_common_voice_de_18826257.wav\n",
      "../../alignment_processing/input/clips/offne/offne_common_voice_de_18826257.wav\n"
     ]
    }
   ],
   "source": [
    "# get rid of the umlaut:\n",
    "#keywords_set = set([\"öffne\", \"hinunter\", \"drei\", \"ja\", \"nein\", \"links\", \"richtig\", \"auf\", \"aus\", \"halt\", \"geh\"])\n",
    "\n",
    "kw_wavs = glob.glob(f\"../../alignment_processing/input/clips/offne/*.wav\")\n",
    "for f in kw_wavs:\n",
    "    #newfile = f.replace(\"ö\", \"o\")\n",
    "    #os.rename(f, newfile)\n",
    "    print(f)\n",
    "    break\n",
    "kw_txts = glob.glob(f\"../../alignment_processing/input/clips/offne/*.txt\")\n",
    "for f in kw_wavs:\n",
    "    #newfile = f.replace(\"ö\", \"o\")\n",
    "    #os.rename(f, newfile)\n",
    "    print(f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run --rm  -v /home/mark/tinyspeech_harvard/alignment_processing:/work/  -t montreal  bin/mfa_align --quiet /work/input /work/lexicon/de.dict /work/lexicon/german_prosodylab.zip /work/output/\n",
    "\n",
    "Setting up corpus information...\n",
    "^NNumber of speakers in corpus: 11, average number of utterances per speaker: 1062.3636363636363\n",
    "/home/mark/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
    "Traceback (most recent call last):\n",
    "  File \"aligner/command_line/align.py\", line 186, in <module>\n",
    "  File \"aligner/command_line/align.py\", line 142, in validate_args\n",
    "  File \"aligner/command_line/align.py\", line 88, in align_corpus\n",
    "  File \"aligner/models.py\", line 129, in validate\n",
    "aligner.exceptions.PronunciationAcousticMismatchError: There were phones in the dictionary that do not have acoustic models: \n",
    "[7] Failed to execute script align\n",
    "```\n",
    "\n",
    "Ok, guess I am using the wrong zip file? Trying `german_prosodylab_g2p.zip` instead:\n",
    "\n",
    "```bash\n",
    "docker run --rm  -v /home/mark/tinyspeech_harvard/alignment_processing:/work/  -t montreal  bin/mfa_align --quiet /work/input /work/lexicon/de.dict /work/lexicon/german_prosodylab_g2p.zip /work/output/\n",
    "\n",
    "Setting up corpus information...\n",
    "Number of speakers in corpus: 11, average number of utterances per speaker: 1062.3636363636363\n",
    "/home/mark/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
    "Creating dictionary information...\n",
    "Traceback (most recent call last):\n",
    "  File \"aligner/command_line/align.py\", line 186, in <module>\n",
    "  File \"aligner/command_line/align.py\", line 142, in validate_args\n",
    "  File \"aligner/command_line/align.py\", line 94, in align_corpus\n",
    "  File \"aligner/aligner/pretrained.py\", line 74, in __init__\n",
    "  File \"aligner/aligner/pretrained.py\", line 122, in setup\n",
    "  File \"aligner/aligner/base.py\", line 89, in setup\n",
    "  File \"aligner/corpus.py\", line 962, in initialize_corpus\n",
    "  File \"aligner/corpus.py\", line 765, in write\n",
    "  File \"aligner/corpus.py\", line 776, in _write_speak_utt\n",
    "  File \"aligner/corpus.py\", line 28, in output_mapping\n",
    "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 0-1: surrogates not allowed\n",
    "[6] Failed to execute script align\n",
    "\n",
    "```\n",
    "\n",
    "Might be caused by `os.walk` running into a directory with an umlaut?\n",
    "\n",
    "Renaming the dir:\n",
    "`alignment_processing/input/clips$ mv öffne offne`\n",
    "\n",
    "Got farther\n",
    "\n",
    "```bash\n",
    "Setting up corpus information...\n",
    "Number of speakers in corpus: 11, average number of utterances per speaker: 1062.3636363636363\n",
    "/home/mark/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
    "Creating dictionary information...\n",
    "Traceback (most recent call last):\n",
    "  File \"aligner/command_line/align.py\", line 186, in <module>\n",
    "  File \"aligner/command_line/align.py\", line 142, in validate_args\n",
    "  File \"aligner/command_line/align.py\", line 94, in align_corpus\n",
    "  File \"aligner/aligner/pretrained.py\", line 74, in __init__\n",
    "  File \"aligner/aligner/pretrained.py\", line 122, in setup\n",
    "  File \"aligner/aligner/base.py\", line 89, in setup\n",
    "  File \"aligner/corpus.py\", line 962, in initialize_corpus\n",
    "  File \"aligner/corpus.py\", line 765, in write\n",
    "  File \"aligner/corpus.py\", line 776, in _write_speak_utt\n",
    "  File \"aligner/corpus.py\", line 28, in output_mapping\n",
    "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 6-7: surrogates not allowed\n",
    "```\n",
    "\n",
    "still goofing though\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_VOICE = \"../../eleven_word_dataset/clips/\"\n",
    "WORKDIR = \"../../alignment_processing_en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right',\n",
       " 'on',\n",
       " 'stop',\n",
       " 'go',\n",
       " 'up',\n",
       " 'left',\n",
       " 'three',\n",
       " 'no',\n",
       " 'off',\n",
       " 'yes',\n",
       " 'down']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwset = list(keywords_set)\n",
    "kwset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -it montreal bin/mfa_align --quiet /work/right/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/right/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['docker',\n",
       " 'run',\n",
       " '--rm',\n",
       " '-v',\n",
       " '/home/mark/tinyspeech_harvard/alignment_processing_en:/work/',\n",
       " '-it',\n",
       " 'montreal',\n",
       " 'bin/mfa_align',\n",
       " '--quiet',\n",
       " '/work/right/',\n",
       " '/work/lexicon/librispeech-lexicon.txt',\n",
       " 'pretrained_models/english.zip',\n",
       " '/work/output/right/']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_workdir = os.path.abspath(WORKDIR)\n",
    "\n",
    "# english\n",
    "kw = kwset[0]\n",
    "mfa = f\"bin/mfa_align --quiet /work/{kw}/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/{kw}/\"\n",
    "# german\n",
    "#KEYWORD = \"richtig\"\n",
    "#mfa = f\"bin/mfa_align -j 5 --quiet /work/input/clips/{KEYWORD}/ /work/lexicon/de.dict /work/lexicon/german_prosodylab.zip /work/output/{KEYWORD}/\"\n",
    "\n",
    "# non-interactive command (no terminal emulation with -i)\n",
    "cmd = f\"\"\"docker run --rm \\\n",
    " -v {abs_workdir}:/work/ \\\n",
    " -t montreal \\\n",
    " {mfa}\"\"\"\n",
    "print(cmd)\n",
    "shlex.split(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/right/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/right/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/on/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/on/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/stop/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/stop/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/go/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/go/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/up/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/up/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/left/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/left/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/three/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/three/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/no/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/no/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/off/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/off/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/yes/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/yes/\n",
      "docker run --rm -v /home/mark/tinyspeech_harvard/alignment_processing_en:/work/ -t montreal bin/mfa_align --quiet /work/down/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/down/\n"
     ]
    }
   ],
   "source": [
    "# interactive version (-i flag) to be run from the terminal\n",
    "for kw in kwset:\n",
    "    mfa = f\"bin/mfa_align --quiet /work/{kw}/ /work/lexicon/librispeech-lexicon.txt pretrained_models/english.zip /work/output/{kw}/\"\n",
    "    cmd = f\"\"\"docker run --rm \\\n",
    "             -v {abs_workdir}:/work/ \\\n",
    "             -it montreal \\\n",
    "             {mfa}\"\"\"\n",
    "    # combine spaces\n",
    "    cmd = \" \".join(cmd.split())\n",
    "    #print(kw, \"\\n\\n\", cmd, \"\\n-\")\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subprocess.Popen(\n",
    "    shlex.split(cmd),\n",
    "    stderr=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up corpus information...\n",
      "Number of speakers in corpus: 1, average number of utterances per speaker: 15.0\n",
      "/home/mark/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "Creating dictionary information...\n",
      "Setting up training data...\n",
      "Calculating MFCCs...\n",
      "Calculating CMVN...\n",
      "Number of speakers in corpus: 1, average number of utterances per speaker: 15.0\n",
      "Done with setup.\n",
      "100% 2/2 [00:03<00:00,  1.84s/it]\n",
      "Done! Everything took 9.433974981307983 seconds\n",
      "  0\n"
     ]
    }
   ],
   "source": [
    "sout, serr = p.communicate()\n",
    "print(sout.decode(\"UTF-8\"), serr.decode(\"UTF-8\"), p.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "tgs = glob.glob(f\"{WORKDIR}/output/halt/*.TextGrid\")\n",
    "print(len(tgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mark/tinyspeech_harvard/tinyspeech/alignment'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output_file: ../../alignment_processing_en/extractions_silencepad/right/common_voice_en_92763.wav already exists and will be overwritten on build\n",
      "WARNING:sox:output_file: ../../alignment_processing_en/extractions_silencepad/right/common_voice_en_92763.wav already exists and will be overwritten on build\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right 1997\n",
      "right ix 0\n",
      "right ix 250\n",
      "right ix 500\n",
      "right ix 750\n",
      "right ix 1000\n",
      "right ix 1250\n",
      "right ix 1500\n",
      "right ix 1750\n",
      "on 1989\n",
      "on ix 0\n",
      "on ix 250\n",
      "on ix 500\n",
      "on ix 750\n",
      "on ix 1000\n",
      "on ix 1250\n",
      "on ix 1500\n",
      "on ix 1750\n",
      "stop 1994\n",
      "stop ix 0\n",
      "stop ix 250\n",
      "stop ix 500\n",
      "stop ix 750\n",
      "stop ix 1000\n",
      "stop ix 1250\n",
      "stop ix 1500\n",
      "stop ix 1750\n",
      "go 1992\n",
      "go ix 0\n",
      "go ix 250\n",
      "go ix 500\n",
      "go ix 750\n",
      "go ix 1000\n",
      "go ix 1250\n",
      "go ix 1500\n",
      "go ix 1750\n",
      "up 1990\n",
      "up ix 0\n",
      "up ix 250\n",
      "up ix 500\n",
      "up ix 750\n",
      "up ix 1000\n",
      "up ix 1250\n",
      "up ix 1500\n",
      "up ix 1750\n",
      "left 1993\n",
      "left ix 0\n",
      "left ix 250\n",
      "left ix 500\n",
      "left ix 750\n",
      "left ix 1000\n",
      "left ix 1250\n",
      "left ix 1500\n",
      "left ix 1750\n",
      "three 1988\n",
      "three ix 0\n",
      "three ix 250\n",
      "three ix 500\n",
      "three ix 750\n",
      "three ix 1000\n",
      "three ix 1250\n",
      "three ix 1500\n",
      "three ix 1750\n",
      "no 1991\n",
      "no ix 0\n",
      "no ix 250\n",
      "no ix 500\n",
      "no ix 750\n",
      "no ix 1000\n",
      "no ix 1250\n",
      "no ix 1500\n",
      "no ix 1750\n",
      "off 1991\n",
      "off ix 0\n",
      "off ix 250\n",
      "off ix 500\n",
      "off ix 750\n",
      "off ix 1000\n",
      "off ix 1250\n",
      "off ix 1500\n",
      "off ix 1750\n",
      "yes 1242\n",
      "yes ix 0\n",
      "yes ix 250\n",
      "yes ix 500\n",
      "yes ix 750\n",
      "yes ix 1000\n",
      "down 1992\n",
      "down ix 0\n",
      "down ix 250\n",
      "down ix 500\n",
      "down ix 750\n",
      "down ix 1000\n",
      "down ix 1250\n",
      "down ix 1500\n",
      "down ix 1750\n"
     ]
    }
   ],
   "source": [
    "SILENCE_PAD = True\n",
    "\n",
    "for kw in kwset:\n",
    "    tgs = glob.glob(f\"{WORKDIR}/output/{kw}/{kw}/*.TextGrid\")\n",
    "    print(kw, len(tgs))\n",
    "    sourcedir = f\"../../eleven_word_dataset/clips/{kw}/\"\n",
    "    \n",
    "    for ix,tgf in enumerate(tgs):\n",
    "        if ix % 250 == 0:\n",
    "            print(kw, \"ix\",ix)\n",
    "        tg = textgrid.TextGrid.fromFile(tgf)\n",
    "        filename_noext = os.path.basename(os.path.splitext(tgf)[0])\n",
    "        for interval in tg[0]:\n",
    "            if interval.mark == kw:\n",
    "                start_s = interval.minTime\n",
    "                end_s = interval.maxTime\n",
    "                #print(start_s, end_s)\n",
    "                \n",
    "                dest = f\"../../alignment_processing_en/extractions_silencepad/{kw}/{filename_noext}.wav\"\n",
    "\n",
    "                wav_path = f\"../../alignment_processing_en/{kw}/{filename_noext}.wav\"\n",
    "                duration = sox.file_info.duration(wav_path)\n",
    "                #if duration < 1:\n",
    "                #    logging.warning(f\"{keyword} clip ix {ix} shorter than 1s\")\n",
    "\n",
    "                if not SILENCE_PAD:\n",
    "                    # with surrounding context\n",
    "                    start_s, end_s = extract_one_second(duration, start_s, end_s)\n",
    "                else:\n",
    "                    if end_s - start_s < 1:\n",
    "                        pad_amt_s = (1. - (end_s - start_s))/2.\n",
    "                    else: # utterance is already longer than 1s, trim instead\n",
    "                        start_s, end_s = extract_one_second(duration, start_s, end_s)\n",
    "                        pad_amt_s = 0\n",
    "\n",
    "\n",
    "                transformer = sox.Transformer()\n",
    "                # alrady 16K\n",
    "                #transformer.convert(samplerate=16000)  # from 48K mp3s\n",
    "                transformer.trim(start_s, end_s)\n",
    "                if not SILENCE_PAD:\n",
    "                    transformer.fade(fade_in_len=0.1, fade_out_len=0.1)\n",
    "                else:\n",
    "                    # use smaller fadein/fadeout since we are capturing just the word\n",
    "                    # TODO(mmaz) is this appropriately sized?\n",
    "                    transformer.fade(fade_in_len=0.025, fade_out_len=0.025)\n",
    "                    transformer.pad(start_duration=pad_amt_s, end_duration=pad_amt_s)\n",
    "                transformer.build(wav_path, dest)\n",
    "                #print(dest)\n",
    "                break # TODO(mmaz) only select the first occurence of the desired wordmark from TextGrid\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got this one wrong: `common_voice_en_18668331.mp3` - lot of noise in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval(0.0, 1.16, None)\n",
      "Interval(1.16, 1.38, ach)\n",
      "Interval(1.38, 1.89, egal)\n",
      "Interval(1.89, 2.06, None)\n",
      "Interval(2.06, 2.23, dann)\n",
      "Interval(2.23, 2.51, nehme)\n",
      "Interval(2.51, 2.66, ich)\n",
      "Interval(2.66, 2.93, halt)\n",
      "Interval(2.93, 3.22, einen)\n",
      "Interval(3.22, 3.59, neuen)\n",
      "Interval(3.59, 4.464, None)\n"
     ]
    }
   ],
   "source": [
    "tg = textgrid.TextGrid.fromFile(tgs[0])\n",
    "\n",
    "for i in range(len(tg[0])):\n",
    "    print(tg[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84, 1.13, 'öffne')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tg[0][2]\n",
    "i.minTime, i.maxTime, i.mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_one_second(duration_s: float, start_s: float, end_s: float):\n",
    "    \"\"\"\n",
    "    return one second around the midpoint between start_s and end_s\n",
    "    \"\"\"\n",
    "    if duration_s < 1:\n",
    "        return (0, duration_s)\n",
    "\n",
    "    center_s = start_s + ((end_s - start_s) / 2.0)\n",
    "\n",
    "    new_start_s = center_s - 0.5\n",
    "    new_end_s = center_s + 0.5\n",
    "\n",
    "    if new_end_s > duration_s:\n",
    "        new_end_s = duration_s\n",
    "        new_start_s = duration_s - 1.0\n",
    "\n",
    "    if new_start_s < 0:\n",
    "        new_start_s = 0\n",
    "        new_end_s = np.minimum(duration_s, new_start_s + 1.0)\n",
    "\n",
    "#     print(\n",
    "#         \"start\",\n",
    "#         new_start_s,\n",
    "#         \"end\",\n",
    "#         new_end_s,\n",
    "#         \"\\nduration\",\n",
    "#         new_end_s - new_start_s,\n",
    "#         \"midpoint\",\n",
    "#         new_start_s + ((new_end_s - new_start_s) / 2.0),\n",
    "#     )\n",
    "    return (new_start_s, new_end_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../alignment_processing//output/input/common_voice_de_18826257.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18666304.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18643584.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_19012318.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18916371.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_19027821.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18958253.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18601528.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18696772.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18624676.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18556969.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18525434.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18527803.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_19153805.TextGrid\n",
      "../../alignment_processing//output/input/common_voice_de_18752770.TextGrid\n"
     ]
    }
   ],
   "source": [
    "for tgf in tgs:\n",
    "    tg = textgrid.TextGrid.fromFile(tgf)\n",
    "    print(tgf)\n",
    "    filename_noext = os.path.basename(os.path.splitext(tgf)[0])\n",
    "    for interval in tg[0]:\n",
    "        print(interval.mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_set = set([\"öffne\", \"hinunter\", \"drei\", \"ja\", \"nein\", \"links\", \"richtig\", \"auf\", \"aus\", \"halt\", \"geh\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867\n",
      "../../alignment_processing//input/clips/richtig/\n",
      "ix 0\n",
      "ix 115\n",
      "ix 230\n",
      "ix 345\n",
      "ix 460\n",
      "ix 575\n",
      "ix 690\n",
      "ix 805\n"
     ]
    }
   ],
   "source": [
    "KEYWORD = \"richtig\"\n",
    "tgs = glob.glob(f\"{WORKDIR}/output/{KEYWORD}/{KEYWORD}/*.TextGrid\")\n",
    "#tgs = glob.glob(f\"../../alignment_processing/output/halt/halt_textgrids/*.TextGrid\")\n",
    "sourcedir = f\"{WORKDIR}/input/clips/{KEYWORD}/\"\n",
    "print(len(tgs))\n",
    "print(sourcedir)\n",
    "\n",
    "PAD = True\n",
    "\n",
    "for ix,tgf in enumerate(tgs):\n",
    "    if ix % 115 == 0:\n",
    "        print(\"ix\",ix)\n",
    "    tg = textgrid.TextGrid.fromFile(tgf)\n",
    "    filename_noext = os.path.basename(os.path.splitext(tgf)[0])\n",
    "    for interval in tg[0]:\n",
    "        if interval.mark == KEYWORD:\n",
    "            start_s = interval.minTime\n",
    "            end_s = interval.maxTime\n",
    "            #print(start_s, end_s)\n",
    "            \n",
    "            wav_path = f\"../../alignment_processing/input/clips/{KEYWORD}/{filename_noext}.wav\"\n",
    "            duration = sox.file_info.duration(wav_path)\n",
    "            #if duration < 1:\n",
    "            #    logging.warning(f\"{keyword} clip ix {ix} shorter than 1s\")\n",
    "\n",
    "            dest = f\"../../alignment_processing/de_extractions_padding/{KEYWORD}/{filename_noext}.wav\"\n",
    "\n",
    "            \n",
    "            if not PAD:\n",
    "                # with surrounding context\n",
    "                start_s, end_s = extract_one_second(duration, start_s, end_s)\n",
    "            else:\n",
    "                if end_s - start_s < 1:\n",
    "                    pad_amt_s = (1. - (end_s - start_s))/2.\n",
    "                else: # utterance is already longer than 1s, trim instead\n",
    "                    start_s, end_s = extract_one_second(duration, start_s, end_s)\n",
    "                    pad_amt_s = 0\n",
    "            \n",
    "            \n",
    "            transformer = sox.Transformer()\n",
    "            # alrady 16K\n",
    "            #transformer.convert(samplerate=16000)  # from 48K mp3s\n",
    "            transformer.trim(start_s, end_s)\n",
    "            if not PAD:\n",
    "                transformer.fade(fade_in_len=0.1, fade_out_len=0.1)\n",
    "            else:\n",
    "                # use smaller fadein/fadeout since we are capturing just the word\n",
    "                # TODO(mmaz) is this appropriately sized?\n",
    "                transformer.fade(fade_in_len=0.025, fade_out_len=0.025)\n",
    "                transformer.pad(start_duration=pad_amt_s, end_duration=pad_amt_s)\n",
    "            transformer.build(wav_path, dest)\n",
    "            #print(dest)\n",
    "            break # TODO(mmaz) only select the first occurence of the desired wordmark from TextGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  Ja, aber das Wachstum ist komplett auf Pump finanziert.\n",
      "1  :  Hätte ich mir ja auch denken können.\n",
      "2  :  Ja nee ist klar.\n",
      "3  :  Der Text lässt sich ja für unsere Zwecke adaptieren.\n",
      "4  :  ja\n",
      "5  :  Das ist ja fürchterlich mit diesen schwarzen Balken überall!\n",
      "6  :  ja\n",
      "7  :  Im Gegensatz zu Tränen und Schweiß ist Speichel nicht salzig, sonst hätte man ja auch ständig Durst.\n",
      "8  :  Kosmetik ist im Grunde genau so unnötig wie Werbung, weil sie ja eine Form der Werbung ist.\n",
      "9  :  ja\n"
     ]
    }
   ],
   "source": [
    "# listen randomly\n",
    "KEYWORD = \"ja\"\n",
    "clips = glob.glob(f\"../../alignment_processing/de_extractions_padding/{KEYWORD}/*.wav\")\n",
    "#clips = glob.glob(f\"../../alignment_processing/de_extractions/{KEYWORD}/*.wav\")\n",
    "random.shuffle(clips)\n",
    "for ix,e in enumerate(clips[:10]):\n",
    "    clip = pydub.AudioSegment.from_wav(e)\n",
    "    fn = f\"../../alignment_processing/input/clips/{KEYWORD}/\" + os.path.splitext(os.path.split(e)[1])[0] + \".txt\"\n",
    "    with open(fn, 'r') as fh:\n",
    "        print(ix, \" : \", fh.read())\n",
    "    play(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label counts\n",
    "wanted_words = [\"auf\", \"halt\", \"ja\", \"nein\", \"richtig\"]\n",
    "datadir = \"../../alignment_processing/de_extractions/\"\n",
    "counts = []\n",
    "for w in wanted_words:\n",
    "    counts.append(len(glob.glob(datadir + w + os.path.sep + \"*.wav\")))\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xticks(range(len(wanted_words)))\n",
    "ax.set_xticklabels(zip(wanted_words, counts))\n",
    "fig.patch.set_facecolor('white')\n",
    "#ax.set_ylim(0,2000)\n",
    "ax.bar(range(len(wanted_words)), counts);\n",
    "fig.set_size_inches(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = samples[\"yes\"].sample(n=1)\n",
    "print(row.sentence.item())\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = glob.glob(\"/home/mark/tinyspeech_harvard/alignment_processing/input/*.wav\")\n",
    "txts = glob.glob(\"/home/mark/tinyspeech_harvard/alignment_processing/input/*.txt\")\n",
    "tgs = glob.glob(\"/home/mark/tinyspeech_harvard/alignment_processing/output/input/*.TextGrid\")\n",
    "for f in wavs + txts + tgs:\n",
    "    os.remove(f)\n",
    "try:\n",
    "    os.rmdir(\"/home/mark/tinyspeech_harvard/alignment_processing/output/input/\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(\"/home/mark/tinyspeech_harvard/alignment_processing/output/oovs_found.txt\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(\"/home/mark/tinyspeech_harvard/alignment_processing/output/utterance_oovs.txt\")\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../common_voice/en/clips/common_voice_en_18483693.mp3\n",
      "../../alignment_processing//input/common_voice_en_18483693.txt\n"
     ]
    }
   ],
   "source": [
    "mp3_path = COMMON_VOICE + row.path.item()\n",
    "print(mp3_path)\n",
    "filename_noext = os.path.basename(os.path.splitext(mp3_path)[0])\n",
    "\n",
    "dest = f\"{WORKDIR}/input/{filename_noext}.wav\"\n",
    "\n",
    "transformer = sox.Transformer()\n",
    "transformer.convert(samplerate=16000)  # from 48K mp3s\n",
    "#transformer.trim(start_s, end_s)\n",
    "#transformer.fade(fade_in_len=0.1, fade_out_len=0.1)\n",
    "transformer.build(mp3_path, dest)\n",
    "\n",
    "utterance = row.sentence.item()\n",
    "transcription = f\"{WORKDIR}/input/{filename_noext}.txt\"\n",
    "print(transcription)\n",
    "with open(transcription, 'w') as fh:\n",
    "    fh.write(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11686\n"
     ]
    }
   ],
   "source": [
    "keywords_set = set([\"öffne\", \"hinunter\", \"drei\", \"ja\", \"nein\", \"links\", \"richtig\", \"auf\", \"aus\", \"halt\", \"geh\"])\n",
    "DATASET = \"../../eleven_word_dataset_de/clips/\"\n",
    "WORKDIR = \"../../alignment_de/\"\n",
    "\n",
    "to_process = []\n",
    "\n",
    "for kw in keywords_set:\n",
    "    clips = glob.glob(DATASET + kw + os.sep + \"*.wav\")\n",
    "    for clip in clips:\n",
    "        #print(clip)\n",
    "        dirname, filename = os.path.split(clip)\n",
    "        txt = dirname + os.path.sep + os.path.splitext(filename)[0] + \".txt\"\n",
    "        to_process.append((clip, txt))\n",
    "        #print(to_process)\n",
    "print(len(to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm  -v /home/mark/tinyspeech_harvard/alignment_de/:/work/  -t montreal  bin/mfa_align --quiet /work/input /work/lexicon/de.dict /work/lexicon/german_prosodylab.zip /work/output/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['docker',\n",
       " 'run',\n",
       " '--rm',\n",
       " '-v',\n",
       " '/home/mark/tinyspeech_harvard/alignment_de/:/work/',\n",
       " '-t',\n",
       " 'montreal',\n",
       " 'bin/mfa_align',\n",
       " '--quiet',\n",
       " '/work/input',\n",
       " '/work/lexicon/de.dict',\n",
       " '/work/lexicon/german_prosodylab.zip',\n",
       " '/work/output/']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfa = \"bin/mfa_align --quiet /work/input /work/lexicon/de.dict /work/lexicon/german_prosodylab.zip /work/output/\"\n",
    "abs_workdir = \"/home/mark/tinyspeech_harvard/alignment_de/\"\n",
    "\n",
    "cmd = f\"\"\"docker run --rm \\\n",
    " -v {abs_workdir}:/work/ \\\n",
    " -t montreal \\\n",
    " {mfa}\"\"\"\n",
    "print(cmd)\n",
    "shlex.split(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../alignment_de/'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORKDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.984444444444444"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 * len(to_process)) / 60 **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_voice_de_18353790.wav\n",
      "../../alignment_de/input/common_voice_de_18353790.wav ../../alignment_de/input/common_voice_de_18353790.txt\n",
      "Setting up corpus information...\n",
      "Number of speakers in corpus: 1, average number of utterances per speaker: 1.0\n",
      "/home/mark/montreal-forced-aligner/lib/aligner/models.py:87: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "Creating dictionary information...\n",
      "Setting up training data...\n",
      "Calculating MFCCs...\n",
      "Calculating CMVN...\n",
      "Number of speakers in corpus: 1, average number of utterances per speaker: 1.0\n",
      "Done with setup.\n",
      "100% 2/2 [00:01<00:00,  1.41it/s]\n",
      "Done! Everything took 4.184454679489136 seconds\n",
      "  0\n",
      "0:00:04.986833\n"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"caution: modifies fs\")\n",
    "errors = []\n",
    "for ix, (wav,txt) in enumerate(to_process):\n",
    "    start = datetime.datetime.now()\n",
    "    shutil.copy2(wav, WORKDIR + \"/input\")\n",
    "    shutil.copy2(txt, WORKDIR + \"/input\")\n",
    "    \n",
    "    dirname, wav_filename = os.path.split(wav)\n",
    "    file_noext = os.path.splitext(wav_filename)[0]\n",
    "    print(wav_filename)\n",
    "    \n",
    "    tmp_wav = WORKDIR + \"input/\" + file_noext + \".wav\"\n",
    "    tmp_txt = WORKDIR + \"input/\" + file_noext + \".txt\"\n",
    "    print(tmp_wav, tmp_txt)\n",
    "    \n",
    "    p = subprocess.Popen(\n",
    "        shlex.split(cmd),\n",
    "        stderr=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "    )\n",
    "    sout, serr = p.communicate()\n",
    "    print(sout.decode(\"UTF-8\"), serr.decode(\"UTF-8\"), p.returncode)\n",
    "    \n",
    "    if p.returncode != 0:\n",
    "        errors.append([ix, sout.decode(\"UTF-8\"), serr.decode(\"UTF-8\") ])\n",
    "        \n",
    "    #os.remove()\n",
    "    \n",
    "    wavs = glob.glob(\"/home/mark/tinyspeech_harvard/alignment_de/input/*.wav\")\n",
    "    txts = glob.glob(\"/home/mark/tinyspeech_harvard/alignment_de/input/*.txt\")\n",
    "    #tgs = glob.glob(\"/home/mark/tinyspeech_harvard/alignment_de/output/input/*.TextGrid\")\n",
    "    tgs = []\n",
    "    for f in wavs + txts + tgs:\n",
    "        os.remove(f)\n",
    "    try:\n",
    "        os.rmdir(\"/home/mark/tinyspeech_harvard/alignment_de/output/input/\")\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    try:\n",
    "        os.remove(\"/home/mark/tinyspeech_harvard/alignment_de/output/oovs_found.txt\")\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    try:\n",
    "        os.remove(\"/home/mark/tinyspeech_harvard/alignment_de/output/utterance_oovs.txt\")\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print(end - start)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
