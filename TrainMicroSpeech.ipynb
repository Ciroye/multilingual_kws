{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb\n",
    "\n",
    "this is just a temporary notebook to generate a formatted string containing flags for `speech_commands/train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../tensorflow/tensorflow/examples/speech_commands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect train/val/test splits for commonvoice filenames\n",
    "ups = glob.glob(\"eleven_word_dataset/extractions_deepspeech/up/*.wav\")\n",
    "downs = glob.glob(\"eleven_word_dataset/extractions_deepspeech/down/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7906637490882568 0.1050328227571116 0.10430342815463166\n",
      "(1371, 1084, 144, 143)\n",
      "0.7899934167215273 0.10335747202106649 0.10664911125740618\n",
      "(1519, 1200, 157, 162)\n"
     ]
    }
   ],
   "source": [
    "def counts(dataset):\n",
    "    total = len(dataset)\n",
    "    training = 0\n",
    "    val = 0\n",
    "    testing = 0\n",
    "    for d in dataset:\n",
    "        result = input_data.which_set(d, 10, 10)\n",
    "        if result == 'validation':\n",
    "            val += 1\n",
    "        elif result == 'testing':\n",
    "            testing += 1\n",
    "        else:\n",
    "            training += 1\n",
    "    print(training/total, val/total, testing/total)\n",
    "    return (total, training, val, testing)\n",
    "print(counts(ups))\n",
    "print(counts(downs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training these words: up,down,left,right,stop,go,off,on,yes,no\n",
      "Training steps in each stage: 12000,3000\n",
      "Learning rate in each stage: 0.001,0.0001\n",
      "Total number of training steps: 15000\n"
     ]
    }
   ],
   "source": [
    "# A comma-delimited list of the words you want to train for.\n",
    "# The options are: yes,no,up,down,left,right,on,off,stop,go\n",
    "# All the other words will be used to train an \"unknown\" label and silent\n",
    "# audio data with no spoken words will be used to train a \"silence\" label.\n",
    "WANTED_WORDS = \"up,down,left,right,stop,go,off,on,yes,no\"\n",
    "\n",
    "# The number of steps and learning rates can be specified as comma-separated\n",
    "# lists to define the rate at each stage. For example,\n",
    "# TRAINING_STEPS=12000,3000 and LEARNING_RATE=0.001,0.0001\n",
    "# will run 12,000 training loops in total, with a rate of 0.001 for the first\n",
    "# 8,000, and 0.0001 for the final 3,000.\n",
    "TRAINING_STEPS = \"12000,3000\"\n",
    "LEARNING_RATE = \"0.001,0.0001\"\n",
    "\n",
    "# Calculate the total number of steps, which is used to identify the checkpoint\n",
    "# file name.\n",
    "TOTAL_STEPS = str(sum(map(lambda string: int(string), TRAINING_STEPS.split(\",\"))))\n",
    "\n",
    "# Print the configuration to confirm it\n",
    "print(\"Training these words: %s\" % WANTED_WORDS)\n",
    "print(\"Training steps in each stage: %s\" % TRAINING_STEPS)\n",
    "print(\"Learning rate in each stage: %s\" % LEARNING_RATE)\n",
    "print(\"Total number of training steps: %s\" % TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of 'silence' and 'unknown' training samples required\n",
    "# to ensure that we have equal number of samples for each label.\n",
    "number_of_labels = WANTED_WORDS.count(',') + 1\n",
    "number_of_total_labels = number_of_labels + 2 # for 'silence' and 'unknown' label\n",
    "equal_percentage_of_training_samples = int(100.0/(number_of_total_labels))\n",
    "SILENT_PERCENTAGE = equal_percentage_of_training_samples\n",
    "UNKNOWN_PERCENTAGE = equal_percentage_of_training_samples\n",
    "\n",
    "# Constants which are shared during training and inference\n",
    "PREPROCESS = 'micro'\n",
    "WINDOW_STRIDE = 20\n",
    "MODEL_ARCHITECTURE = 'tiny_conv' # Other options include: single_fc, conv,\n",
    "                      # low_latency_conv, low_latency_svdf, tiny_embedding_conv\n",
    "\n",
    "# Constants used during training only\n",
    "VERBOSITY = 'WARN'\n",
    "EVAL_STEP_INTERVAL = '1000'\n",
    "SAVE_STEP_INTERVAL = '1000'\n",
    "\n",
    "# Constants for training directories and filepaths\n",
    "#DATASET_DIR =  'dataset/'\n",
    "DATASET_DIR =  'eleven_word_dataset/extractions_gcloud/'\n",
    "LOGS_DIR = 'logs/'\n",
    "TRAIN_DIR = 'train/' # for training checkpoints and other files.\n",
    "\n",
    "# Constants for inference directories and filepaths\n",
    "import os\n",
    "MODELS_DIR = 'models'\n",
    "#if not os.path.exists(MODELS_DIR):\n",
    "#  os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = os.path.join(MODELS_DIR, 'model.pb')\n",
    "MODEL_TFLITE = os.path.join(MODELS_DIR, 'model.tflite')\n",
    "FLOAT_MODEL_TFLITE = os.path.join(MODELS_DIR, 'float_model.tflite')\n",
    "MODEL_TFLITE_MICRO = os.path.join(MODELS_DIR, 'model.cc')\n",
    "SAVED_MODEL = os.path.join(MODELS_DIR, 'saved_model')\n",
    "\n",
    "QUANT_INPUT_MIN = 0.0\n",
    "QUANT_INPUT_MAX = 26.0\n",
    "QUANT_INPUT_RANGE = QUANT_INPUT_MAX - QUANT_INPUT_MIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original:\n",
    "```\n",
    "#!python ../tensorflow/tensorflow/examples/speech_commands/train.py \\\n",
    "!echo\\\n",
    "--data_dir={DATASET_DIR} \\\n",
    "--wanted_words={WANTED_WORDS} \\\n",
    "--silence_percentage={SILENT_PERCENTAGE} \\\n",
    "--unknown_percentage={UNKNOWN_PERCENTAGE} \\\n",
    "--preprocess={PREPROCESS} \\\n",
    "--window_stride={WINDOW_STRIDE} \\\n",
    "--model_architecture={MODEL_ARCHITECTURE} \\\n",
    "--how_many_training_steps={TRAINING_STEPS} \\\n",
    "--learning_rate={LEARNING_RATE} \\\n",
    "--train_dir={TRAIN_DIR} \\\n",
    "--summaries_dir={LOGS_DIR} \\\n",
    "--verbosity={VERBOSITY} \\\n",
    "--eval_step_interval={EVAL_STEP_INTERVAL} \\\n",
    "--save_step_interval={SAVE_STEP_INTERVAL}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--data_dir=eleven_word_dataset/extractions_gcloud/ --wanted_words=up,down,left,right,stop,go,off,on,yes,no --background_volume=0.0 --silence_percentage=8 --unknown_percentage=8 --preprocess=micro --window_stride=20 --model_architecture=tiny_conv --how_many_training_steps=12000,3000 --learning_rate=0.001,0.0001 --train_dir=train/ --summaries_dir=logs/ --verbosity=WARN --eval_step_interval=1000 --save_step_interval=1000\n"
     ]
    }
   ],
   "source": [
    "#!python ../tensorflow/tensorflow/examples/speech_commands/train.py \\\n",
    "!echo\\\n",
    "--data_dir={DATASET_DIR} \\\n",
    "--wanted_words={WANTED_WORDS} \\\n",
    "--background_volume=0.0\\\n",
    "--silence_percentage={SILENT_PERCENTAGE} \\\n",
    "--unknown_percentage={UNKNOWN_PERCENTAGE} \\\n",
    "--preprocess={PREPROCESS} \\\n",
    "--window_stride={WINDOW_STRIDE} \\\n",
    "--model_architecture={MODEL_ARCHITECTURE} \\\n",
    "--how_many_training_steps={TRAINING_STEPS} \\\n",
    "--learning_rate={LEARNING_RATE} \\\n",
    "--train_dir={TRAIN_DIR} \\\n",
    "--summaries_dir={LOGS_DIR} \\\n",
    "--verbosity={VERBOSITY} \\\n",
    "--eval_step_interval={EVAL_STEP_INTERVAL} \\\n",
    "--save_step_interval={SAVE_STEP_INTERVAL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cp -r ../speech_commands/_background_noise_ ../tinyspeech/eleven_word_dataset/extractions_deepspeech/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From new directory:\n",
    "```bash\n",
    "eleven_no_bkgd $ python ../tensorflow/tensorflow/examples/speech_commands/train.py --data_dir=../tinyspeech/eleven_word_dataset/extractions_gcloud/ --wanted_words=up,down,left,right,stop,go,off,on,yes,no --background_volume=0.0 --silence_percentage=8 --unknown_percentage=8 --preprocess=micro --window_stride=20 --model_architecture=tiny_conv --how_many_training_steps=12000,3000 --learning_rate=0.001,0.0001 --train_dir=train/ --summaries_dir=logs/ --verbosity=WARN --eval_step_interval=1000 --save_step_interval=1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python ../tensorflow/tensorflow/examples/speech_commands/train.py --data_dir=../tinyspeech/eleven_word_dataset/extractions_deepspeech/ --wanted_words=up,down,left,right,stop,go,off,on,yes,no --silence_percentage=8 --unknown_percentage=8 --preprocess=micro --window_stride=20 --model_architecture=tiny_conv --how_many_training_steps=12000,3000 --learning_rate=0.001,0.0001 --train_dir=train/ --summaries_dir=logs/ --verbosity=WARN --eval_step_interval=1000 --save_step_interval=1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cross-validation (ignores most of these flags)\n",
    "\n",
    "```bash\n",
    "python ../tensorflow/tensorflow/examples/speech_commands/eval.py --start_checkpoint=train/tiny_conv.ckpt-15000 --data_dir=../speech_commands/ --wanted_words=up,down,left,right,stop,go,off,on,yes,no --silence_percentage=8 --unknown_percentage=8 --preprocess=micro --window_stride=20 --model_architecture=tiny_conv --how_many_training_steps=12000,3000 --learning_rate=0.001,0.0001 --train_dir=train/ --summaries_dir=logs/ --verbosity=WARN --eval_step_interval=1000 --save_step_interval=1000\n",
    "\n",
    "###\n",
    "\n",
    "python ../tensorflow/tensorflow/examples/speech_commands/eval.py --start_checkpoint=train/tiny_conv.ckpt-15000 --data_dir=../speech_commands/ --wanted_words=up,down --silence_percentage=25 --unknown_percentage=25 --preprocess=micro --window_stride=20 --model_architecture=tiny_conv --how_many_training_steps=12000,3000 --learning_rate=0.001,0.0001 --train_dir=train/ --summaries_dir=logs/ --verbosity=WARN --eval_step_interval=1000 --save_step_interval=1000\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
