{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sox\n",
    "import wave\n",
    "import logging\n",
    "import pydub \n",
    "from pydub.playback import play\n",
    "import time\n",
    "import csv\n",
    "import glob\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from typing import Set, List, Dict\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_path = \"../mozilla_common_voice/clips/\" # english corpus\n",
    "train_df = pd.read_csv(\"../mozilla_common_voice/train.tsv\", sep=\"\\t\")\n",
    "val_df = pd.read_csv(\"../mozilla_common_voice/validated.tsv\", sep=\"\\t\")\n",
    "print(\"number of mp3s in training set: \", train_df.shape[0], \" - validated set: \", val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are NaNs in val_df.sentence\n",
    "val_df[val_df.sentence.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.dropna(subset=['sentence'],inplace=True)\n",
    "print(val_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a micro dataset of 50 clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clips=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_to_sample(df, ix, clips_path):\n",
    "    mp3_path = clips_path + df.iloc[ix].path\n",
    "    clip = pydub.AudioSegment.from_mp3(mp3_path)\n",
    "    play(clip)\n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randint(df.shape[0])\n",
    "listen_to_sample(df=df, ix=sample, clips_path=clips_path)\n",
    "selected_clips.append(sample)\n",
    "print(len(selected_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"warning: overwrites\")\n",
    "df.iloc[selected_clips].to_csv(\n",
    "    \"selected_clips.tsv\", sep=\"\\t\", quoting=csv.QUOTE_MINIMAL, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"selected_clips.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, r in selected.iterrows():\n",
    "    mp3_path = clips_path + r.path\n",
    "    shutil.copy2(mp3_path, \"./micro_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run `word_separator/transcribe_word_time_offsets.py` on `./micro_dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select keywords for word separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_filter(keyword_set: Set[str], sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    inserts a new column containing a list of keywords present from \n",
    "    tokenizing the existing 'sentence' column\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "    return list(filter(lambda w: w in keyword_set, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\n",
    "tf_set = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_set = set([\"up\", \"down\", \"three\", \"yes\", \"no\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"])\n",
    "\n",
    "# TODO(MMAZ) inefficient\n",
    "val_df['keywords'] = val_df.sentence.apply(functools.partial(clean_and_filter, keywords_set))\n",
    "\n",
    "val_df.dropna(subset=[\"keywords\"], inplace=True)\n",
    "usable = val_df.loc[val_df.keywords.transform(len) > 0]\n",
    "print(\"mp3s containing desired keywords\", usable.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert usable from slice:\n",
    "usable = usable.copy()\n",
    "\n",
    "for kw in keywords_set:\n",
    "    # is the current keyword in the list of present keywords?\n",
    "    # usable[kw] is a boolean column indicating keyword presence\n",
    "    usable[kw] = usable.keywords.apply(lambda l: kw in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [k for k in keywords_set]\n",
    "counts = [usable[k].value_counts().loc[True] for k in keywords_set]\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_ylim(0,10000)\n",
    "ax.bar(range(len(labels)), counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable[\"yes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to tsv\n",
    "usable.drop(columns=[\"keywords\"], axis=1).to_csv(\n",
    "    \"keywords_listen.tsv\", sep=\"\\t\", quoting=csv.QUOTE_MINIMAL, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = os.path.getsize(\"keywords_listen.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b / 1024 ** 2 #MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_csv(\"keywords_listen.tsv\", sep=\"\\t\")\n",
    "print(keywords.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select examples each from keywords where the column [\"keywords\"] == True\n",
    "NUM_SAMPLES = 2000\n",
    "samples = {}\n",
    "for k in keywords_set:\n",
    "    if keywords[k].value_counts().loc[True] > NUM_SAMPLES:\n",
    "        #are there more than NUM_SAMPLES examples?\n",
    "        samples[k] = keywords[keywords[k]].sample(n=NUM_SAMPLES)\n",
    "    else:\n",
    "        # use them all\n",
    "        samples[k] = keywords[keywords[k]]\n",
    "        logging.warning(f\"for keyword {k}, there are not enough examples to sample\")\n",
    "    print(\"Keyword\", k, \":\", samples[k].shape[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = samples[\"go\"]\n",
    "sample = np.random.randint(q.shape[0])\n",
    "print(q.iloc[sample].sentence)\n",
    "listen_to_sample(df=q, ix=sample, clips_path=clips_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"eleven_word_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory structure\n",
    "raise ValueError(\"caution: script operates on fs\")\n",
    "cur = os.getcwd()\n",
    "print(f\"operating in {cur}\")\n",
    "for dest in [\"clips\", \"extractions_gcloud\", \"extractions_deepspeech\", \"transcripts_gcloud\"]:\n",
    "    for k in keywords_set:\n",
    "        newdir = f\"{parent_dir}/{dest}/{k}/\"\n",
    "        os.makedirs(newdir)\n",
    "        print(newdir)\n",
    "os.makedirs(f\"{parent_dir}/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tsvs of NUM_SAMPLES examples selected for each of the keywords\n",
    "for name, df in samples.items():\n",
    "    # remove all the keywords-present columns\n",
    "    df.drop(columns=keywords_set, axis=1).to_csv(\n",
    "        f\"{parent_dir}/{name}.tsv\", sep=\"\\t\", quoting=csv.QUOTE_MINIMAL, index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy source mp3s into correct subdirectory\n",
    "for keyword, df in samples.items():\n",
    "    for _,r in df.iterrows():\n",
    "        mp3_path = clips_path + r.path\n",
    "        shutil.copy2(mp3_path, f\"./{parent_dir}/clips/{keyword}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total length of all samples\n",
    "total_time = 0\n",
    "for keyword, _ in samples.items():\n",
    "    clips = glob.glob(f\"./{parent_dir}/clips/{keyword}/*.mp3\")\n",
    "    print(\"keyword\", keyword, len(clips))\n",
    "    kw_time = 0\n",
    "    for c in clips:\n",
    "        s = pydub.AudioSegment.from_mp3(c)\n",
    "        d = s.duration_seconds\n",
    "        kw_time += d\n",
    "    print(kw_time)\n",
    "    total_time += kw_time\n",
    "print(\"TOTAL\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "98096.73599999992 / 60**2 # hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract keywords using Google Cloud STT API Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword(timings, keyword):\n",
    "    \"\"\"returns either (start,end) in seconds, or None\"\"\"\n",
    "    for timing in timings:\n",
    "        word = timing['word']\n",
    "        \n",
    "        # TODO(MMAZ) note this only extracts the first word for now\n",
    "        # i.e., \"tap up, then up, then down\" will only return the first \"up\"\n",
    "        if word == keyword:\n",
    "            return timing['start_time'], timing['end_time']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count number of found words via GCloud STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws = [\"up\",\"down\",\"left\",\"right\",\"stop\",\"go\",\"off\",\"on\",\"yes\",\"no\",\"three\"]\n",
    "missing = {w:0 for w in kws}\n",
    "found = {w:0 for w in kws}\n",
    "for keyword in kws:\n",
    "    #df = pd.read_csv(f\"./eleven_word_dataset/{keyword}.tsv\", sep=\"\\t\")\n",
    "    transcripts = glob.glob(f\"eleven_word_dataset/transcripts_gcloud/{keyword}/*.json\")\n",
    "    for fname in transcripts:\n",
    "        with open(fname, 'r') as fh:\n",
    "            try:\n",
    "                transcription = json.load(fh)\n",
    "            except json.JSONDecodeError as e:\n",
    "                #logging.warning(f\"no transcription returned by GCP STT API for sentence {ix}\")\n",
    "                missing[keyword] += 1\n",
    "                continue\n",
    "        result = find_keyword(transcription[\"timings\"], keyword)\n",
    "        if result is None:\n",
    "            missing[keyword] += 1\n",
    "        else:\n",
    "            found[keyword] += 1\n",
    "    \n",
    "#     for ix, r in df.iterrows():\n",
    "#         fname = f\"./eleven_word_dataset/transcripts_gcloud/{keyword}/{r.path}.json\"\n",
    "#         if not os.path.exists(fname):\n",
    "#             missing[keyword] += 1\n",
    "#             print(fname)\n",
    "#             break\n",
    "print(\"missing\", missing)\n",
    "print(\"found\", found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_one_second(duration_s: float, start_s: float, end_s: float):\n",
    "    \"\"\"\n",
    "    return one second around the midpoint between start_s and end_s\n",
    "    \"\"\"\n",
    "    if duration_s < 1:\n",
    "        return (0, duration_s)\n",
    "\n",
    "    center_s = start_s + ((end_s - start_s) / 2.0)\n",
    "\n",
    "    new_start_s = center_s - 0.5\n",
    "    new_end_s = center_s + 0.5\n",
    "\n",
    "    if new_end_s > duration_s:\n",
    "        new_end_s = duration_s\n",
    "        new_start_s = duration_s - 1.0\n",
    "\n",
    "    if new_start_s < 0:\n",
    "        new_start_s = 0\n",
    "        new_end_s = np.minimum(duration_s, new_start_s + 1.0)\n",
    "\n",
    "#     print(\n",
    "#         \"start\",\n",
    "#         new_start_s,\n",
    "#         \"end\",\n",
    "#         new_end_s,\n",
    "#         \"\\nduration\",\n",
    "#         new_end_s - new_start_s,\n",
    "#         \"midpoint\",\n",
    "#         new_start_s + ((new_end_s - new_start_s) / 2.0),\n",
    "#     )\n",
    "    return (new_start_s, new_end_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"eleven_word_dataset\"\n",
    "\n",
    "log_location = f\"{parent_dir}/logs/gcloud.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[%(asctime)s ::: %(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename=log_location),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"eleven_word_dataset\"\n",
    "kws = [\"up\",\"down\",\"left\",\"right\",\"stop\",\"go\",\"off\",\"on\",\"yes\",\"no\",\"three\"]\n",
    "for keyword in kws:\n",
    "    #df = pd.read_csv(f\"./eleven_word_dataset/{keyword}.tsv\", sep=\"\\t\")\n",
    "    transcripts = glob.glob(f\"{dataset}/transcripts_gcloud/{keyword}/*.json\")\n",
    "    for ix,fname in enumerate(transcripts):\n",
    "        \n",
    "        # keep track of current keyword in separate file\n",
    "        if ix % 100 == 0:\n",
    "            with open(\"./tmp/current_gcloud.txt\", 'a') as fh:\n",
    "                fh.write(f\"{keyword} {ix}\\n\")\n",
    "\n",
    "        with open(fname, 'r') as fh:\n",
    "            try:\n",
    "                transcription = json.load(fh)\n",
    "            except json.JSONDecodeError as e:\n",
    "                #logging.warning(f\"no transcription returned by GCP STT API for sentence {ix}\")\n",
    "                missing[keyword] += 1\n",
    "                continue\n",
    "        result = find_keyword(transcription[\"timings\"], keyword)\n",
    "        if result is None:\n",
    "            logging.warning(f\"keyword {keyword} not found in inference for sentence {ix}:\\n - {transcription['transcript']}\")\n",
    "            continue\n",
    "        start_s, end_s = result    \n",
    "        if end_s - start_s > 1:\n",
    "            logging.warning(f\"{keyword} clip ix: {ix} timestamps are longer than one second\")\n",
    "\n",
    "        mp3_fn = os.path.split(fname)[-1][:-5] #elide .json from the filename\n",
    "        mp3_path = f\"{dataset}/clips/{keyword}/{mp3_fn}\"\n",
    "        \n",
    "        duration = sox.file_info.duration(mp3_path)\n",
    "        if duration < 1:\n",
    "            logging.warning(f\"{keyword} clip ix {ix} shorter than 1s\")\n",
    "        \n",
    "        \n",
    "        dest = f\"./{dataset}/extractions_gcloud/{keyword}/{mp3_path}.wav\"\n",
    "    \n",
    "        start_s, end_s = extract_one_second(duration, start_s, end_s)\n",
    "\n",
    "        # to listen:\n",
    "        #clip = pydub.AudioSegment.from_wav()\n",
    "        #play(clip)\n",
    "        #extraction = clip[start_s * 1000:end_s * 1000]\n",
    "        #play(extraction)\n",
    "\n",
    "        transformer = sox.Transformer()\n",
    "        transformer.trim(start_s, end_s)\n",
    "        transformer.fade(fade_in_len=0.1, fade_out_len=0.1)\n",
    "        dest = f\"./{dataset}/extractions_gcloud/{keyword}/{mp3_fn}.wav\"\n",
    "        transformer.build(mp3_path, dest)\n",
    "        # run 'soxi' on the output wav to inspect encoding parameters\n",
    "\n",
    "        # listen to the processed audio:\n",
    "        #play(pydub.AudioSegment.from_wav(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"three\"\n",
    "df = pd.read_csv(f\"./micro_dataset/{keyword}.tsv\", sep=\"\\t\")\n",
    "print(f\"{keyword}.tsv # of examples:\", df.shape[0])\n",
    "\n",
    "for ix, (_, r) in enumerate(df.iterrows()):\n",
    "    if ix != 30:\n",
    "        continue\n",
    "    if ix % 10 == 0:\n",
    "        print(\"progress\", ix)\n",
    "    mp3_path = f\"./micro_dataset/clips/{keyword}/\" + r.path\n",
    "    \n",
    "    fname = f\"./micro_dataset/transcripts_googlecloud/{keyword}/{r.path}.json\"\n",
    "    with open(fname, 'r') as fh:\n",
    "        try:\n",
    "            transcription = json.load(fh)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.warning(f\"no transcription returned by GCP STT API for sentence {ix}\")\n",
    "            continue\n",
    "\n",
    "    result = find_keyword(transcription[\"timings\"], keyword)\n",
    "    if result is None:\n",
    "        logging.warning(f\"keyword {keyword} not found in inference for sentence {ix}:\\n - {transcription['transcript']}\")\n",
    "        continue\n",
    "\n",
    "    start_s, end_s = result    \n",
    "    \n",
    "    dest = f\"./micro_dataset/extractions_googlecloud/{keyword}/{r.path}.wav\"\n",
    "    \n",
    "    # convert to wav (will overwrite existing dest)\n",
    "    transformer = sox.Transformer()\n",
    "    transformer.convert(samplerate=16000)\n",
    "    transformer.trim(start_s, end_s)\n",
    "    transformer.build(mp3_path, dest)\n",
    "    \n",
    "    # to listen\n",
    "    clip = pydub.AudioSegment.from_wav(dest)\n",
    "    play(clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to word splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"selected_clips_yes_no_three.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(MMAZ) lower() and remove punctuation, etc\n",
    "# pasted from https://stackoverflow.com/a/32558749\n",
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_to_split_on_boundaries(timings, clip, keywords_set=None):\n",
    "    if keywords_set is not None:\n",
    "        words = set([t[\"word\"] for t in timings])\n",
    "        if words.isdisjoint(keywords_set):\n",
    "            print(\"No keywords found in the transcription\")\n",
    "    for ix, timing in enumerate(timings):\n",
    "        word = timing['word']\n",
    "        if keywords_set and word not in keywords_set:\n",
    "            continue\n",
    "        start_ms = timing['start_time'] * 1000\n",
    "        end_ms = timing['end_time'] * 1000\n",
    "        print(f\"word {ix}: {word} \\n - start_time: {timing['start_time']:.3f} - end_time: {timing['end_time']:.3f}\")\n",
    "        play(clip[start_ms:end_ms])\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, row in selected.iterrows():\n",
    "    print(f\"Sample: {ix}\")\n",
    "    fname = \"./keywords_transcriptions/\" + row.path + \".json\"\n",
    "    with open(fname, 'r') as fh:\n",
    "        transcription = json.load(fh)\n",
    "    gt = row.sentence\n",
    "    print(f\"Groundtruth: {gt}\")\n",
    "    text = transcription['transcript']\n",
    "    print(f\"Inference: {text}\")\n",
    "    print(\"Edit Distance:\", levenshteinDistance(gt, text))\n",
    "    print(\"\\n--\\n\")\n",
    "    clip = listen_to_sample(df=selected, ix=ix, clips_path=clips_path)\n",
    "    listen_to_split_on_boundaries(transcription['timings'], clip, keywords_set=keyword_set)\n",
    "    time.sleep(4)\n",
    "    clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
