{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sox\n",
    "import wave\n",
    "import logging\n",
    "import pydub \n",
    "from pydub.playback import play\n",
    "import time\n",
    "import csv\n",
    "import glob\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from typing import Set, List, Dict\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_path = \"../mozilla_common_voice/clips/\" # english corpus\n",
    "train_df = pd.read_csv(\"../mozilla_common_voice/train.tsv\", sep=\"\\t\")\n",
    "val_df = pd.read_csv(\"../mozilla_common_voice/validated.tsv\", sep=\"\\t\")\n",
    "print(\"number of mp3s in training set: \", train_df.shape[0], \" - validated set: \", val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are NaNs in val_df.sentence\n",
    "val_df[val_df.sentence.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.dropna(subset=['sentence'],inplace=True)\n",
    "print(val_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a micro dataset of 50 clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clips=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_to_sample(df, ix, clips_path):\n",
    "    mp3_path = clips_path + df.iloc[ix].path\n",
    "    clip = pydub.AudioSegment.from_mp3(mp3_path)\n",
    "    play(clip)\n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randint(df.shape[0])\n",
    "listen_to_sample(df=df, ix=sample, clips_path=clips_path)\n",
    "selected_clips.append(sample)\n",
    "print(len(selected_clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"warning: overwrites\")\n",
    "df.iloc[selected_clips].to_csv(\n",
    "    \"selected_clips.tsv\", sep=\"\\t\", quoting=csv.QUOTE_MINIMAL, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"selected_clips.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, r in selected.iterrows():\n",
    "    mp3_path = clips_path + r.path\n",
    "    shutil.copy2(mp3_path, \"./micro_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run `word_separator/transcribe_word_time_offsets.py` on `./micro_dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select keywords for word separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_filter(keyword_set: Set[str], sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    inserts a new column containing a list of keywords present from \n",
    "    tokenizing the existing 'sentence' column\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    words = [word.lower() for word in tokens if word.isalpha()]\n",
    "    return list(filter(lambda w: w in keyword_set, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\n",
    "tf_set = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_set = set([\"up\", \"down\", \"three\", \"yes\", \"no\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"])\n",
    "\n",
    "# TODO(MMAZ) inefficient\n",
    "val_df['keywords'] = val_df.sentence.apply(functools.partial(clean_and_filter, keywords_set))\n",
    "\n",
    "val_df.dropna(subset=[\"keywords\"], inplace=True)\n",
    "usable = val_df.loc[val_df.keywords.transform(len) > 0]\n",
    "print(\"mp3s containing desired keywords\", usable.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert usable from slice:\n",
    "usable = usable.copy()\n",
    "\n",
    "for kw in keywords_set:\n",
    "    # is the current keyword in the list of present keywords?\n",
    "    # usable[kw] is a boolean column indicating keyword presence\n",
    "    usable[kw] = usable.keywords.apply(lambda l: kw in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [k for k in keywords_set]\n",
    "counts = [usable[k].value_counts().loc[True] for k in keywords_set]\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_ylim(0,10000)\n",
    "ax.bar(range(len(labels)), counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable[\"yes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to tsv\n",
    "usable.drop(columns=[\"keywords\"], axis=1).to_csv(\n",
    "    \"keywords_listen.tsv\", sep=\"\\t\", quoting=csv.QUOTE_MINIMAL, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = os.path.getsize(\"keywords_listen.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b / 1024 ** 2 #MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = pd.read_csv(\"keywords_listen.tsv\", sep=\"\\t\")\n",
    "print(keywords.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select examples each from keywords where the column [\"keywords\"] == True\n",
    "NUM_SAMPLES = 2000\n",
    "samples = {}\n",
    "for k in keywords_set:\n",
    "    if keywords[k].value_counts().loc[True] > NUM_SAMPLES:\n",
    "        #are there more than NUM_SAMPLES examples?\n",
    "        samples[k] = keywords[keywords[k]].sample(n=NUM_SAMPLES)\n",
    "    else:\n",
    "        # use them all\n",
    "        samples[k] = keywords[keywords[k]]\n",
    "        logging.warning(f\"for keyword {k}, there are not enough examples to sample\")\n",
    "    print(\"Keyword\", k, \":\", samples[k].shape[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = samples[\"go\"]\n",
    "sample = np.random.randint(q.shape[0])\n",
    "print(q.iloc[sample].sentence)\n",
    "listen_to_sample(df=q, ix=sample, clips_path=clips_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no help for it.\n"
     ]
    }
   ],
   "source": [
    "q = samples[\"no\"]\n",
    "sample = np.random.randint(q.shape[0])\n",
    "print(q.iloc[sample].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"eleven_word_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory structure\n",
    "raise ValueError(\"caution: script operates on fs\")\n",
    "cur = os.getcwd()\n",
    "print(f\"operating in {cur}\")\n",
    "for dest in [\"clips\", \"extractions_gcloud\", \"extractions_deepspeech\", \"transcripts_gcloud\"]:\n",
    "    for k in keywords_set:\n",
    "        newdir = f\"{parent_dir}/{dest}/{k}/\"\n",
    "        os.makedirs(newdir)\n",
    "        print(newdir)\n",
    "os.makedirs(f\"{parent_dir}/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tsvs of NUM_SAMPLES examples selected for each of the keywords\n",
    "for name, df in samples.items():\n",
    "    # remove all the keywords-present columns\n",
    "    df.drop(columns=keywords_set, axis=1).to_csv(\n",
    "        f\"{parent_dir}/{name}.tsv\", sep=\"\\t\", quoting=csv.QUOTE_MINIMAL, index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy source mp3s into correct subdirectory\n",
    "for keyword, df in samples.items():\n",
    "    for _,r in df.iterrows():\n",
    "        mp3_path = clips_path + r.path\n",
    "        shutil.copy2(mp3_path, f\"./{parent_dir}/clips/{keyword}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total length of all samples\n",
    "total_time = 0\n",
    "for keyword, _ in samples.items():\n",
    "    clips = glob.glob(f\"./{parent_dir}/clips/{keyword}/*.mp3\")\n",
    "    print(\"keyword\", keyword, len(clips))\n",
    "    kw_time = 0\n",
    "    for c in clips:\n",
    "        s = pydub.AudioSegment.from_mp3(c)\n",
    "        d = s.duration_seconds\n",
    "        kw_time += d\n",
    "    print(kw_time)\n",
    "    total_time += kw_time\n",
    "print(\"TOTAL\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "98096.73599999992 / 60**2 # hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract keywords using Google Cloud STT API Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword(timings, keyword):\n",
    "    \"\"\"returns either (start,end) in seconds, or None\"\"\"\n",
    "    for timing in timings:\n",
    "        word = timing['word']\n",
    "        \n",
    "        # TODO(MMAZ) note this only extracts the first word for now\n",
    "        # i.e., \"tap up, then up, then down\" will only return the first \"up\"\n",
    "        if word == keyword:\n",
    "            return timing['start_time'], timing['end_time']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count number of found words via GCloud STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws = [\"up\",\"down\",\"left\",\"right\",\"stop\",\"go\",\"off\",\"on\",\"yes\",\"no\",\"three\"]\n",
    "missing = {w:0 for w in kws}\n",
    "found = {w:0 for w in kws}\n",
    "for keyword in kws:\n",
    "    #df = pd.read_csv(f\"./eleven_word_dataset/{keyword}.tsv\", sep=\"\\t\")\n",
    "    transcripts = glob.glob(f\"eleven_word_dataset/transcripts_gcloud/{keyword}/*.json\")\n",
    "    for fname in transcripts:\n",
    "        with open(fname, 'r') as fh:\n",
    "            try:\n",
    "                transcription = json.load(fh)\n",
    "            except json.JSONDecodeError as e:\n",
    "                #logging.warning(f\"no transcription returned by GCP STT API for sentence {ix}\")\n",
    "                missing[keyword] += 1\n",
    "                continue\n",
    "        result = find_keyword(transcription[\"timings\"], keyword)\n",
    "        if result is None:\n",
    "            missing[keyword] += 1\n",
    "        else:\n",
    "            found[keyword] += 1\n",
    "    \n",
    "#     for ix, r in df.iterrows():\n",
    "#         fname = f\"./eleven_word_dataset/transcripts_gcloud/{keyword}/{r.path}.json\"\n",
    "#         if not os.path.exists(fname):\n",
    "#             missing[keyword] += 1\n",
    "#             print(fname)\n",
    "#             break\n",
    "print(\"missing\", missing)\n",
    "print(\"found\", found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_one_second(duration_s: float, start_s: float, end_s: float):\n",
    "    \"\"\"\n",
    "    return one second around the midpoint between start_s and end_s\n",
    "    \"\"\"\n",
    "    if duration_s < 1:\n",
    "        return (0, duration_s)\n",
    "\n",
    "    center_s = start_s + ((end_s - start_s) / 2.0)\n",
    "\n",
    "    new_start_s = center_s - 0.5\n",
    "    new_end_s = center_s + 0.5\n",
    "\n",
    "    if new_end_s > duration_s:\n",
    "        new_end_s = duration_s\n",
    "        new_start_s = duration_s - 1.0\n",
    "\n",
    "    if new_start_s < 0:\n",
    "        new_start_s = 0\n",
    "        new_end_s = np.minimum(duration_s, new_start_s + 1.0)\n",
    "\n",
    "#     print(\n",
    "#         \"start\",\n",
    "#         new_start_s,\n",
    "#         \"end\",\n",
    "#         new_end_s,\n",
    "#         \"\\nduration\",\n",
    "#         new_end_s - new_start_s,\n",
    "#         \"midpoint\",\n",
    "#         new_start_s + ((new_end_s - new_start_s) / 2.0),\n",
    "#     )\n",
    "    return (new_start_s, new_end_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"eleven_word_dataset\"\n",
    "\n",
    "log_location = f\"{parent_dir}/logs/gcloud.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[%(asctime)s ::: %(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(filename=log_location),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example parameters for `speech_commands`\n",
    "\n",
    "```bash\n",
    "soxi speech_commands/stop/234d6a48_nohash_2.wav\n",
    "\n",
    "Input File     : 'speech_commands/stop/234d6a48_nohash_2.wav'\n",
    "Channels       : 1\n",
    "Sample Rate    : 16000\n",
    "Precision      : 16-bit\n",
    "Duration       : 00:00:01.00 = 16000 samples ~ 75 CDDA sectors\n",
    "File Size      : 32.0k\n",
    "Bit Rate       : 256k\n",
    "Sample Encoding: 16-bit Signed Integer PCM\n",
    "\n",
    "```\n",
    "\n",
    "For `common voice`:\n",
    "\n",
    "```bash\n",
    "soxi mozilla_common_voice/clips/common_voice_en_19293740.mp3\n",
    "\n",
    "Input File     : 'mozilla_common_voice/clips/common_voice_en_19293740.mp3'\n",
    "Channels       : 1\n",
    "Sample Rate    : 48000\n",
    "Precision      : 16-bit\n",
    "Duration       : 00:00:04.82 = 231552 samples ~ 361.8 CDDA sectors\n",
    "File Size      : 38.6k\n",
    "Bit Rate       : 64.1k\n",
    "Sample Encoding: MPEG audio (layer I, II or III)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"eleven_word_dataset\"\n",
    "kws = [\"up\", \"down\", \"left\", \"right\", \"stop\", \"go\", \"off\", \"on\", \"yes\", \"no\", \"three\"]\n",
    "missing = {kw:0 for kw in kws}\n",
    "for keyword in kws:\n",
    "    # df = pd.read_csv(f\"./eleven_word_dataset/{keyword}.tsv\", sep=\"\\t\")\n",
    "    transcripts = glob.glob(f\"{dataset}/transcripts_gcloud/{keyword}/*.json\")\n",
    "    for ix, fname in enumerate(transcripts):\n",
    "\n",
    "        # keep track of current keyword in separate file\n",
    "        if ix % 100 == 0:\n",
    "            with open(\"./tmp/current_gcloud.txt\", \"a\") as fh:\n",
    "                fh.write(f\"{keyword} {ix}\\n\")\n",
    "\n",
    "        with open(fname, \"r\") as fh:\n",
    "            try:\n",
    "                transcription = json.load(fh)\n",
    "            except json.JSONDecodeError as e:\n",
    "                # logging.warning(\n",
    "                #     f\"no transcription returned by GCP STT API for sentence {ix}\")\n",
    "                missing[keyword] += 1\n",
    "                continue\n",
    "        result = find_keyword(transcription[\"timings\"], keyword)\n",
    "        if result is None:\n",
    "            logging.warning(\n",
    "                f\"keyword {keyword} not found in inference for sentence {ix}:\\n\"\n",
    "                f\" - {transcription['transcript']}\"\n",
    "            )\n",
    "            continue\n",
    "        start_s, end_s = result\n",
    "        if end_s - start_s > 1:\n",
    "            logging.warning(\n",
    "                f\"{keyword} clip ix: {ix} timestamps are longer than one second\"\n",
    "            )\n",
    "\n",
    "        mp3_fn = os.path.split(fname)[-1][:-5]  # elide .json from the filename\n",
    "        mp3_path = f\"{dataset}/clips/{keyword}/{mp3_fn}\"\n",
    "\n",
    "        duration = sox.file_info.duration(mp3_path)\n",
    "        if duration < 1:\n",
    "            logging.warning(f\"{keyword} clip ix {ix} shorter than 1s\")\n",
    "\n",
    "        dest = f\"./{dataset}/extractions_gcloud/{keyword}/{mp3_path}.wav\"\n",
    "\n",
    "        start_s, end_s = extract_one_second(duration, start_s, end_s)\n",
    "\n",
    "        # to listen:\n",
    "        # clip = pydub.AudioSegment.from_wav()\n",
    "        # play(clip)\n",
    "        # extraction = clip[start_s * 1000:end_s * 1000]\n",
    "        # play(extraction)\n",
    "\n",
    "        transformer = sox.Transformer()\n",
    "        transformer.convert(samplerate=16000)  # from 48K mp3s\n",
    "        transformer.trim(start_s, end_s)\n",
    "        transformer.fade(fade_in_len=0.1, fade_out_len=0.1)\n",
    "        dest = f\"./{dataset}/extractions_gcloud/{keyword}/{mp3_fn}.wav\"\n",
    "        transformer.build(mp3_path, dest)\n",
    "        # run 'soxi' on the output wav to inspect encoding parameters\n",
    "\n",
    "        # listen to the processed audio:\n",
    "        # play(pydub.AudioSegment.from_wav(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"three\"\n",
    "df = pd.read_csv(f\"./micro_dataset/{keyword}.tsv\", sep=\"\\t\")\n",
    "print(f\"{keyword}.tsv # of examples:\", df.shape[0])\n",
    "\n",
    "for ix, (_, r) in enumerate(df.iterrows()):\n",
    "    if ix != 30:\n",
    "        continue\n",
    "    if ix % 10 == 0:\n",
    "        print(\"progress\", ix)\n",
    "    mp3_path = f\"./micro_dataset/clips/{keyword}/\" + r.path\n",
    "    \n",
    "    fname = f\"./micro_dataset/transcripts_googlecloud/{keyword}/{r.path}.json\"\n",
    "    with open(fname, 'r') as fh:\n",
    "        try:\n",
    "            transcription = json.load(fh)\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.warning(f\"no transcription returned by GCP STT API for sentence {ix}\")\n",
    "            continue\n",
    "\n",
    "    result = find_keyword(transcription[\"timings\"], keyword)\n",
    "    if result is None:\n",
    "        logging.warning(f\"keyword {keyword} not found in inference for sentence {ix}:\\n - {transcription['transcript']}\")\n",
    "        continue\n",
    "\n",
    "    start_s, end_s = result    \n",
    "    \n",
    "    dest = f\"./micro_dataset/extractions_googlecloud/{keyword}/{r.path}.wav\"\n",
    "    \n",
    "    # convert to wav (will overwrite existing dest)\n",
    "    transformer = sox.Transformer()\n",
    "    transformer.convert(samplerate=16000)\n",
    "    transformer.trim(start_s, end_s)\n",
    "    transformer.build(mp3_path, dest)\n",
    "    \n",
    "    # to listen\n",
    "    clip = pydub.AudioSegment.from_wav(dest)\n",
    "    play(clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to word splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"selected_clips_yes_no_three.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(MMAZ) lower() and remove punctuation, etc\n",
    "# pasted from https://stackoverflow.com/a/32558749\n",
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_to_split_on_boundaries(timings, clip, keywords_set=None):\n",
    "    if keywords_set is not None:\n",
    "        words = set([t[\"word\"] for t in timings])\n",
    "        if words.isdisjoint(keywords_set):\n",
    "            print(\"No keywords found in the transcription\")\n",
    "    for ix, timing in enumerate(timings):\n",
    "        word = timing['word']\n",
    "        if keywords_set and word not in keywords_set:\n",
    "            continue\n",
    "        start_ms = timing['start_time'] * 1000\n",
    "        end_ms = timing['end_time'] * 1000\n",
    "        print(f\"word {ix}: {word} \\n - start_time: {timing['start_time']:.3f} - end_time: {timing['end_time']:.3f}\")\n",
    "        play(clip[start_ms:end_ms])\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, row in selected.iterrows():\n",
    "    print(f\"Sample: {ix}\")\n",
    "    fname = \"./keywords_transcriptions/\" + row.path + \".json\"\n",
    "    with open(fname, 'r') as fh:\n",
    "        transcription = json.load(fh)\n",
    "    gt = row.sentence\n",
    "    print(f\"Groundtruth: {gt}\")\n",
    "    text = transcription['transcript']\n",
    "    print(f\"Inference: {text}\")\n",
    "    print(\"Edit Distance:\", levenshteinDistance(gt, text))\n",
    "    print(\"\\n--\\n\")\n",
    "    clip = listen_to_sample(df=selected, ix=ix, clips_path=clips_path)\n",
    "    listen_to_split_on_boundaries(transcription['timings'], clip, keywords_set=keyword_set)\n",
    "    time.sleep(4)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CommonVoice Speech Commands\n",
    "\n",
    "https://voice.mozilla.org/en/datasets\n",
    "\n",
    "Single-word target segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26070 entries, 0 to 26069\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   client_id   26070 non-null  object\n",
      " 1   path        26070 non-null  object\n",
      " 2   sentence    26070 non-null  object\n",
      " 3   up_votes    26070 non-null  int64 \n",
      " 4   down_votes  26070 non-null  int64 \n",
      " 5   age         9437 non-null   object\n",
      " 6   gender      9385 non-null   object\n",
      " 7   accent      6017 non-null   object\n",
      " 8   locale      26070 non-null  object\n",
      " 9   segment     26070 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "val_path = \"../commonvoice_singleword/cv-corpus-5-singleword/en/validated.tsv\"\n",
    "val_df = pd.read_csv(val_path, sep='\\t')\n",
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no NaN values:\n",
    "val_df[val_df.sentence.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Firefox',\n",
       " 'Hey',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'four',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'one',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'three',\n",
       " 'two',\n",
       " 'yes',\n",
       " 'zero'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set([w for w in val_df.sentence])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seven': 1916,\n",
       " 'eight': 1822,\n",
       " 'zero': 1840,\n",
       " 'four': 1807,\n",
       " 'one': 1914,\n",
       " 'nine': 1932,\n",
       " 'three': 1667,\n",
       " 'no': 1886,\n",
       " 'yes': 1989,\n",
       " 'Firefox': 1868,\n",
       " 'five': 1832,\n",
       " 'Hey': 1894,\n",
       " 'six': 1912,\n",
       " 'two': 1791}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts = {}\n",
    "for w in words:\n",
    "    word_df = val_df[val_df.sentence == w]\n",
    "    wordcounts[w] = word_df.shape[0]\n",
    "wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id     6b9ee6a8405cdb1c7404bb6376d18022eee4823c012616...\n",
       "path                               common_voice_en_22074788.mp3\n",
       "sentence                                                Firefox\n",
       "up_votes                                                      2\n",
       "down_votes                                                    1\n",
       "age                                                         NaN\n",
       "gender                                                      NaN\n",
       "accent                                                      NaN\n",
       "locale                                                       en\n",
       "segment                                    Singleword Benchmark\n",
       "Name: 65, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.iloc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = val_df.iloc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "output_file: ../singleword_train/firefox/common_voice_en_22074788.mp3.wav already exists and will be overwritten on build\n",
      "WARNING:sox:output_file: ../singleword_train/firefox/common_voice_en_22074788.mp3.wav already exists and will be overwritten on build\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../commonvoice_singleword/cv-corpus-5-singleword/en/clips/common_voice_en_22074788.mp3 \n",
      " ../singleword_train/firefox/common_voice_en_22074788.mp3.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = sox.Transformer()\n",
    "transformer.convert(samplerate=16000)  # from 48K mp3s\n",
    "mp3_path = clips + row.path\n",
    "dest = f\"{dsdir}/{row.sentence.lower()}/{row.path}.wav\"\n",
    "print(mp3_path, \"\\n\",dest)\n",
    "transformer.build(mp3_path, dest)\n",
    "# run 'soxi' on the output wav to inspect encoding parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row 65:\n",
    "\n",
    "`singleword_train/firefox/common_voice_en_22074788.mp3.wav`\n",
    "\n",
    "Contains `firefox` said twice\n",
    "\n",
    "6 seconds long \n",
    "\n",
    "```\n",
    "soxi ../singleword_train/firefox/common_voice_en_22074788.mp3.wav\n",
    "\n",
    "Input File     : '../singleword_train/firefox/common_voice_en_22074788.mp3.wav'\n",
    "Channels       : 1\n",
    "Sample Rate    : 16000\n",
    "Precision      : 16-bit\n",
    "Duration       : 00:00:06.31 = 100992 samples ~ 473.4 CDDA sectors\n",
    "File Size      : 202k\n",
    "Bit Rate       : 256k\n",
    "Sample Encoding: 16-bit Signed Integer PCM\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = pydub.AudioSegment.from_wav(\"../singleword_train/firefox/common_voice_en_22074788.mp3.wav\")\n",
    "f = pydub.AudioSegment.from_wav(\"../commonvoice_singleword/en_wav_ext/common_voice_en_22074788.mp3.wav\")\n",
    "play(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `extract_loudest_section` results in `<mic noises> firefo-` on the above example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = \"../singleword_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 725\n"
     ]
    }
   ],
   "source": [
    "# after running extract_loudest_section, organize files into directories\n",
    "raise ValueError(\"copies a large number of files\")\n",
    "\n",
    "clips_dir = \"../commonvoice_singleword/en_wav_ext\"\n",
    "missing = 0\n",
    "for ix,r in val_df.iterrows():\n",
    "    mp3_name = r.path\n",
    "    target_word = r.sentence.lower()\n",
    "    wav_file = f\"{clips_dir}/{mp3_name}.wav\"\n",
    "    if not os.path.exists(wav_file):\n",
    "        missing += 1\n",
    "        continue\n",
    "    target = f\"{dest_dir}/{target_word}/\"\n",
    "    shutil.copy2(wav_file, target)\n",
    "print(\"Missing\", missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "725 missing files between `validated.txt`, `sox` wav conversion (some failed), and after running `extract_loudest_section`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seven 1867\n",
      "eight 1729\n",
      "zero 1818\n",
      "four 1769\n",
      "one 1855\n",
      "nine 1894\n",
      "three 1620\n",
      "no 1835\n",
      "yes 1923\n",
      "Firefox 1846\n",
      "five 1785\n",
      "Hey 1833\n",
      "six 1832\n",
      "two 1739\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    d = os.listdir(f\"{dest_dir}/{w.lower()}/\")\n",
    "    print(w, len(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
